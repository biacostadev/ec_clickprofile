{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e4efe14-99a2-4513-a11f-11d70548f622",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Objetivo:**\n",
    "### Prever se um **Cliente** irá realizar uma compra nos próximos **30 dias**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04ae2504-c603-4cab-a248-6b5ea4d1c52e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Importando e Tranformando os dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05d7bf14-8edc-4f90-b425-c5f7867266f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07b84bd4-cfdf-426d-839f-e55ab1bd3411",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1ae21e7-6dc4-4bb8-b9c3-8059a9b377b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5d178b9-2bcd-4b69-9950-69b6edab5db1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tabela_bronze = \"estudo.default.tvendas_bronze\"\n",
    "tabela_cluster_gold = \"estudo.default.tcluster_cli_gold\"\n",
    "tabela_modelo_previsao_compra = \"estudo.default.tprev_compra_silver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2df382b0-e360-46db-8c65-06356ee87dcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_raw_spark = spark.table(tabela_bronze)\n",
    "df_raw = df_raw_spark.toPandas()\n",
    "\n",
    "df_clientes_spark = spark.table(tabela_cluster_gold).filter(F.col(\"ds_cluster\") == 'Cliente Comum').select(\"fk_contact\", \"ds_cluster\")\n",
    "df_clientes = df_clientes_spark.toPandas()\n",
    "\n",
    "# Verificando os tipos das colunas\n",
    "df_raw.info()\n",
    "df_clientes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6632fb45-97ef-40cc-85e6-bf56b89cc8a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 🎯 **Segmento Foco: Clientes Comuns**\n",
    "\n",
    "Optamos por focar o modelo nos **Clientes Comuns**, pois são o grupo com **histórico de compras consistente**, **features bem definidas** e **alto potencial de previsibilidade**. Mesmo sendo uma porcentagem pequena, representam o maior retorno possível com campanhas bem direcionadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1293bee9-f718-410a-ac55-2e2cfb77ad4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pegando somente os clientes do segmento \"Cliente Comum\"\n",
    "clientes_comuns = df_clientes[df_clientes['ds_cluster'] == 'Cliente Comum']['fk_contact'].reset_index(drop=True).to_frame()\n",
    "\n",
    "print(f\"Total de Clientes Comuns: {len(clientes_comuns)}\")\n",
    "clientes_comuns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "318abd57-b64e-4e70-aa65-cf80d8f91a86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Tratando os dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d1c8bcd-ddb7-455c-9c12-cedada4dd707",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Passando as colunas para o tipo date\n",
    "df_raw['date_purchase'] = pd.to_datetime(df_raw['date_purchase'])\n",
    "df_raw['time_purchase'] = pd.to_datetime(df_raw['time_purchase'], format='%H:%M:%S').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32cd79ba-dda5-4922-9243-2cfcc2695b5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_raw['gmv_success'] = df_raw['gmv_success'].astype(float)\n",
    "\n",
    "valores_negativo_ou_zero = df_raw[df_raw['gmv_success'] <= 0]\n",
    "\n",
    "print(f'Existem {valores_negativo_ou_zero[\"gmv_success\"].count()} valores menores ou igual a zero')\n",
    "\n",
    "# Excluindo as linhas com valores negativos\n",
    "df_raw = df_raw[~df_raw['nk_ota_localizer_id'].isin(valores_negativo_ou_zero['nk_ota_localizer_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "145b11ce-90aa-4528-aa98-2de03a22e016",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e346381-57e8-432d-b3ee-c7df87c12672",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##  Divisão dos Dados: **Clientes de Treino** & **Clientes de Teste**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ace375ac-c4f4-4610-b177-db6e2f652cef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **80%** dos clientes serão usados para **treinar** o modelo  \n",
    "\n",
    "> **20%** serão guardados para **testar** o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba1ad1f1-3592-43a9-924b-81e2aa1c7fb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definindo uma semente aleatória\n",
    "SEED = 358477\n",
    "\n",
    "# A função train_test_split separa os clientes em treino e teste automaticamente\n",
    "clientes_treino, clientes_teste = train_test_split(\n",
    "    clientes_comuns['fk_contact'],\n",
    "    test_size=0.2,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Número de clientes separados para treino: {len(clientes_treino)}\")\n",
    "print(f\"Número de clientes separados para teste: {len(clientes_teste)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de627864-eb04-4671-a5b4-39591ce4e8d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Estamos filtrando o dataframe de compras para possuir apenas os clientes comuns\n",
    "df_compras_treino = df_raw[df_raw['fk_contact'].isin(clientes_treino)]\n",
    "df_compras_teste = df_raw[df_raw['fk_contact'].isin(clientes_teste)]\n",
    "\n",
    "print(f\"\\nNúmero de compras no conjunto de treino: {len(df_compras_treino)}\")\n",
    "print(f\"Número de compras no conjunto de teste: {len(df_compras_teste)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b42c4a4-5a68-4dd9-a7df-98e98b19ef26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Feature Engeneering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7bcd1b9-0eb1-4e4f-8d8c-75ff3e525ef8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Criando Features para o Conjunto de **Treino**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b79a132f-d71b-43ca-af24-61904b437761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ultima_data_treino = df_compras_treino['date_purchase'].max()\n",
    "data_corte_treino = ultima_data_treino - pd.DateOffset(days=30)\n",
    "\n",
    "print(f\"A data de corte para o treino será: {data_corte_treino.date()}\")\n",
    "\n",
    "# Filtrando as compras até a data de corte\n",
    "features_treino_df = df_compras_treino[df_compras_treino['date_purchase'] <= data_corte_treino].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07d6992a-6b2f-4115-8a84-b2b00dcd6b88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Não podemos pegar as métricas RFM do df_cluster pois estaríamos influenciando os dados, causando um vazemento de dados entre os clientes de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb41001d-193b-41c3-a5b1-3fbe7bf4a5ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Recência, Frequência e Valor Gasto ---\n",
    "df_final_treino = features_treino_df.groupby('fk_contact').agg(\n",
    "    recencia=('date_purchase', lambda x: (data_corte_treino - x.max()).days),\n",
    "    frequencia=('date_purchase', 'count'),\n",
    "    valor_total_gasto=('gmv_success', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# --- Média de Tempo entre Compras ---\n",
    "df_intervalos = features_treino_df.sort_values(by=['fk_contact', 'date_purchase'])\n",
    "df_intervalos['intervalo_dias'] = df_intervalos.groupby('fk_contact')['date_purchase'].diff().dt.days\n",
    "\n",
    "df_media_tempo = df_intervalos.groupby('fk_contact')['intervalo_dias'].mean().reset_index()\n",
    "df_media_tempo.columns = ['fk_contact', 'media_tempo_entre_compras']\n",
    "\n",
    "df_final_treino = pd.merge(df_final_treino, df_media_tempo, on='fk_contact', how='left')\n",
    "\n",
    "# --- Numero de Rotas Únicas ---\n",
    "features_treino_df['rota'] = features_treino_df['place_origin_departure'] + ' -> ' + features_treino_df['place_destination_departure']\n",
    "df_rotas_unicas = features_treino_df.groupby('fk_contact')['rota'].nunique().reset_index()\n",
    "df_rotas_unicas.columns = ['fk_contact', 'num_rotas_unicas']\n",
    "\n",
    "df_final_treino = pd.merge(df_final_treino, df_rotas_unicas, on='fk_contact', how='left')\n",
    "\n",
    "# --- Número de Viagens com Retorno ---\n",
    "df_com_retorno = features_treino_df[features_treino_df['place_destination_return'] != '0'].groupby('fk_contact').size().reset_index(name='num_viagens_com_retorno')\n",
    "\n",
    "df_final_treino = pd.merge(df_final_treino, df_com_retorno, on='fk_contact', how='left')\n",
    "\n",
    "# --- Média de Passagens por Viagem ---\n",
    "df_media_passagens = features_treino_df.groupby('fk_contact')['total_tickets_quantity_success'].mean().reset_index()\n",
    "df_media_passagens.columns = ['fk_contact', 'media_passagens_por_viagem']\n",
    "\n",
    "df_final_treino = pd.merge(df_final_treino, df_media_passagens, on='fk_contact', how='left')\n",
    "\n",
    "# Dias desde a primeira compra (tempo de vida do cliente)\n",
    "df_primeira_compra = features_treino_df.groupby('fk_contact')['date_purchase'].min().reset_index()\n",
    "df_primeira_compra.columns = ['fk_contact', 'primeira_compra']\n",
    "df_primeira_compra['dias_desde_primeira_compra'] = (data_corte_treino - df_primeira_compra['primeira_compra']).dt.days\n",
    "\n",
    "df_final_treino = pd.merge(df_final_treino, df_primeira_compra[['fk_contact', 'dias_desde_primeira_compra']], on='fk_contact', how='left')  \n",
    "\n",
    "\n",
    "# --- Tratamento de Nulos ---\n",
    "df_final_treino.fillna(0, inplace=True)\n",
    "\n",
    "df_final_treino.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70df5f03-9755-4f90-800b-8d41f536448b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Preparação do x_treino**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2542703-0b46-476d-813a-74cb5619bc5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Garantimos que o x_treino contenha exatamente todos os clientes separados para o treino\n",
    "x_treino = pd.DataFrame(clientes_treino, columns=['fk_contact'])\n",
    "x_treino = pd.merge(x_treino, df_final_treino, on='fk_contact', how='left')\n",
    "\n",
    "x_treino.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d5edf91-75f0-4106-bba3-8a68e9cc321a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Criando a Variável Alvo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8edbed74-f25a-4179-8b7b-a96ce4217ce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "alvo_df_treino = df_compras_treino[df_compras_treino['date_purchase'] > data_corte_treino]\n",
    "\n",
    "clientes_compradores_treino = alvo_df_treino['fk_contact'].unique()\n",
    "\n",
    "x_treino['alvo'] = x_treino['fk_contact'].isin(clientes_compradores_treino).astype(int)\n",
    "x_treino.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50fc4235-c966-4e8e-ac94-b25468ab89d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Filtrando as colunas para o x_treino e y_treino**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eae39ca-55b3-40c7-9dbe-ef48091e3921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_treino = x_treino['alvo']\n",
    "x_treino = x_treino.drop(columns=['fk_contact', 'alvo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56302b11-d27c-42f9-a38e-934189dd5703",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee432547-1ebb-405c-92a5-06e181ddbe81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Criando Features para o Conjunto de **Teste**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dba4700b-0a68-4801-9c20-29a60bc8c0b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Iremos aplicar as mesmas etapas, porém no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "277291ab-fc84-4300-891b-4d869012ceec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ultima_data_teste = df_compras_teste['date_purchase'].max()\n",
    "data_corte_teste = ultima_data_teste - pd.DateOffset(days=30)\n",
    "\n",
    "features_teste_df = df_compras_teste[df_compras_teste['date_purchase'] <= data_corte_teste].copy()\n",
    "\n",
    "print(f\"A data de corte para o teste será: {data_corte_teste.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34ff5f5c-87d5-415a-a41b-7b128612d9f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Recência, Frequência e Valor Gasto ---\n",
    "df_final_teste = features_teste_df.groupby('fk_contact').agg(\n",
    "    recencia=('date_purchase', lambda x: (data_corte_teste - x.max()).days),\n",
    "    frequencia=('date_purchase', 'count'),\n",
    "    valor_total_gasto=('gmv_success', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# --- Média de Tempo entre Compras ---\n",
    "df_intervalos_teste = features_teste_df.sort_values(by=['fk_contact', 'date_purchase'])\n",
    "df_intervalos_teste['intervalo_dias'] = df_intervalos_teste.groupby('fk_contact')['date_purchase'].diff().dt.days\n",
    "df_media_tempo_teste = df_intervalos_teste.groupby('fk_contact')['intervalo_dias'].mean().reset_index()\n",
    "df_media_tempo_teste.columns = ['fk_contact', 'media_tempo_entre_compras']\n",
    "\n",
    "df_final_teste = pd.merge(df_final_teste, df_media_tempo_teste, on='fk_contact', how='left')\n",
    "\n",
    "# --- Numero de Rotas Únicas ---\n",
    "features_teste_df['rota'] = features_teste_df['place_origin_departure'] + ' -> ' + features_teste_df['place_destination_departure']\n",
    "df_rotas_unicas_teste = features_teste_df.groupby('fk_contact')['rota'].nunique().reset_index()\n",
    "df_rotas_unicas_teste.columns = ['fk_contact', 'num_rotas_unicas']\n",
    "\n",
    "df_final_teste = pd.merge(df_final_teste, df_rotas_unicas_teste, on='fk_contact', how='left')\n",
    "\n",
    "# --- Número de Viagens com Retorno ---\n",
    "df_com_retorno_teste = features_teste_df[features_teste_df['place_destination_return'] != '0'].groupby('fk_contact').size().reset_index(name='num_viagens_com_retorno')\n",
    "\n",
    "df_final_teste = pd.merge(df_final_teste, df_com_retorno_teste, on='fk_contact', how='left')\n",
    "\n",
    "# --- Média de Passagens por Viagem ---\n",
    "df_media_passagens_teste = features_teste_df.groupby('fk_contact')['total_tickets_quantity_success'].mean().reset_index()\n",
    "df_media_passagens_teste.columns = ['fk_contact', 'media_passagens_por_viagem']\n",
    "\n",
    "df_final_teste = pd.merge(df_final_teste, df_media_passagens_teste, on='fk_contact', how='left')\n",
    "\n",
    "# Dias desde a primeira compra (tempo de vida do cliente)\n",
    "df_primeira_compra = features_teste_df.groupby('fk_contact')['date_purchase'].min().reset_index()\n",
    "df_primeira_compra.columns = ['fk_contact', 'primeira_compra']\n",
    "df_primeira_compra['dias_desde_primeira_compra'] = (data_corte_teste - df_primeira_compra['primeira_compra']).dt.days\n",
    "df_final_teste = pd.merge(df_final_teste, df_primeira_compra[['fk_contact', 'dias_desde_primeira_compra']], on='fk_contact', how='left')  \n",
    "\n",
    "\n",
    "# --- Tratamento de Nulos ---\n",
    "df_final_teste.fillna(0, inplace=True)\n",
    "\n",
    "df_final_teste.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e24f487b-fd6f-4ac4-ac96-897759c9e21b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Preparação do x_teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6108747-e3f8-4f8a-84f8-1394b3150e66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_teste = pd.DataFrame(clientes_teste.values, columns=['fk_contact'])\n",
    "x_teste = pd.merge(x_teste, df_final_teste, on='fk_contact', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21d9e089-11f8-4b58-9a68-3dbe42f4ed85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Criando a Variável Alvo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0554f6f2-6303-4b94-b5c6-b31e91b2e0ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "alvo_teste_df = df_compras_teste[df_compras_teste['date_purchase'] > data_corte_teste]\n",
    "\n",
    "clientes_compradores_teste = alvo_teste_df['fk_contact'].unique()\n",
    "x_teste['alvo'] = x_teste['fk_contact'].isin(clientes_compradores_teste).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "498a5d17-374d-4e2f-9dde-d5199de5d7e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Filtrando as colunas para o x_teste e y_teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34691c8b-f3e2-4393-a04a-b64c0806ea7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_teste = x_teste['alvo']\n",
    "x_teste = x_teste.drop(columns=['fk_contact', 'alvo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d16d18f9-7ad3-4396-bd89-2dc592b33917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0edbfea-f4da-4f9b-889c-5bb27bf54c91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Verificando a distribuição de compradores e não compradores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa9f2b51-ea04-475e-9a87-9007af7ea5d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_treino.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0db869b6-4e13-4318-ae44-e31d9565e39b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_teste.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8aa9bf93-6212-4347-b2b7-57c859ae75c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### A variável alvo segue segue a mesma proporção tanto no **y_treino** como no **y_teste**, isso é muito bom para nosso modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df05de16-a1e9-41a5-8036-02ed3f67a4b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Dummy Classifier**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b8d9c46-7d1b-42ae-a49d-4ffd2f57bff6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Iremos começar com o **Dummy Classifier** para ter nossa linha de base de **precisão** e **recall**. O modelo irá “chutar” que todos os clientes **não** vão fazer uma compra no mês seguinte, pois essa é a variável mais frequente.  \n",
    "\n",
    "Como, em média, **70%** dos clientes não compraram, a **acurácia será de 70%**.  \n",
    "\n",
    "Porém, queremos ver os acertos quando se trata de quem **realmente comprou**. Nesse caso, a **precisão é de apenas 27%** e o **recall de 30%**, resultando em um **F1-score de 28%**, o que não é nada bom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2f859d0-db58-4ebb-9183-5f9ec6c10bd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# A estratégia 'stratified' faz previsões aleatóris, mas mantendo a mesma distribuição de classes do conjunto de treino.\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=SEED)\n",
    "\n",
    "# Treinando o modelo com os mesmos dados de treino\n",
    "dummy_clf.fit(x_treino, y_treino)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred_dummy = dummy_clf.predict(x_teste)\n",
    "\n",
    "# Exibindo o relatório de classificação\n",
    "print(\"Relatório de Classificação (Dummy Classifier):\")\n",
    "print(classification_report(y_teste, y_pred_dummy, target_names=['Não Comprou (0)', 'Comprou (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be233905-dcb8-4f8f-ba6b-09f2070913a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7d7a1ea-9337-4a78-a31e-e419ceaa4c57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**XGBoost** é um algoritmo poderoso de *gradient boosting* que oferece alta precisão e rapidez, mesmo em problemas com classes desbalanceadas.\n",
    "\n",
    "Com ajustes de pesos para as classes, ele melhora a predição da classe minoritária, sendo ideal para identificar **não compradores**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac49b24d-9cd7-40d2-909c-902b14c8ab00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculando o peso da classe positiva (quem comprou). Isso ajuda o XGBoost a dar mais atenção pra essa classe minoritária.\n",
    "peso = y_treino.value_counts()[0] / y_treino.value_counts()[1]\n",
    "print(f\"Peso calculado para o treino final: {peso:.2f}\")\n",
    "\n",
    "\n",
    "# Montamos o pipeline final que vai escalar os dados\n",
    "pipeline_xgb_final = Pipeline([\n",
    "    ('scaler', StandardScaler()),    # Normaliza os dados pra facilitar o treino\n",
    "    ('xgb', xgb.XGBClassifier(\n",
    "        learning_rate=0.05,          # Taxa de aprendizado \n",
    "        max_depth=7,                 # Profundidade das árvores (complexidade do modelo)\n",
    "        n_estimators=600,            # Quantidade de árvores que o modelo vai criar\n",
    "        colsample_bytree=0.8,        # Amostra de colunas usadas em cada árvore, ajuda a evitar overfitting\n",
    "        objective='binary:logistic', # Problema é de classificação binária\n",
    "        scale_pos_weight=peso,       # Ajusta o peso da classe positiva pra lidar com desbalanceamento\n",
    "        eval_metric='logloss',       # Métrica usada pra avaliar a perda durante o treino\n",
    "        random_state=SEED            # Pra deixar os resultados reproduzíveis\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Treinando o modelo XGBoost final com os dados de treino\n",
    "pipeline_xgb_final.fit(x_treino, y_treino) \n",
    "\n",
    "# Fazendo a previsão com os dados de teste\n",
    "y_pred_final = pipeline_xgb_final.predict(x_teste)  \n",
    "\n",
    "# Calcula a acurácia geral do modelo, mesmo não sendo a melhor métrica para avaliar o modelo\n",
    "accuracy_final = accuracy_score(y_teste, y_pred_final)\n",
    "print(f\"Acurácia  do Modelo: {accuracy_final:.2%}\")\n",
    "\n",
    "# Mostra o relatório completo de classificação, mostrando precisão, recall e F1 por classe\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_teste, y_pred_final, target_names=['Não Comprou (0)', 'Comprou (1)']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c87f3e41-3186-4fd3-90e4-4e46374bc1c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Trade-Off: Precisão x Recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41770ed4-07ea-4b38-b022-151e6553aadb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Nosso modelo obteve uma média de **65%** entre a precisão e o recall, porém, na nossa estratégia, iremos focar em aumentar a **recall**. Queremos uma 'certeza' de pelo menos **30%**, ou seja, o modelo só vai dizer que o cliente vai comprar se tiver mais de **30% de certeza**.  \n",
    " \n",
    "##### Ao diminuir o limite de decisão, aumentamos o recall, mas corremos o risco de reduzir a precisão, já que o modelo passará a classificar mais casos como positivos — inclusive alguns que não comprarão. É uma **troca (trade-off)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77501ddf-6ecb-4651-8d72-43996d34bf84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pegar as probabilidades do modelo para o conjunto de teste \n",
    "y_probabilities_final = pipeline_xgb_final.predict_proba(x_teste)[:, 1]\n",
    "\n",
    "# 2. Definir o nossa linha de trade-off. Vamos usar um limiar de 0.3, que é um pouco mais baixo que o padrão de 0.5.\n",
    "nosso_limiar_ideal = 0.3\n",
    "\n",
    "# Aplicar essa regra para transformar as probabilidades em previsão final (0 ou 1)\n",
    "y_pred_com_limiar_ajustado = (y_probabilities_final >= nosso_limiar_ideal).astype(int)\n",
    "\n",
    "# Mostrar o resultado\n",
    "\n",
    "print(classification_report(y_teste, y_pred_com_limiar_ajustado, target_names=['Não Comprou (0)', 'Comprou (1)']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f16d9cf-8a2b-4184-8dbb-1f163635cdd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Analisando a Matriz de Confusao**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f487bf96-3a2e-48c2-bfb8-18130b08a0a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- ✅ Verdadeiro Negativo: O modelo **acertou** que 771 clientes **não iriam comprar**\n",
    "- ✅ Verdadeiro Positivo: O modelo **acertou** que 344 clientes **iriam comprar**\n",
    "\n",
    "- ❌ Falso Positivo: O modelo previu que 292 clientes **iriam comprar**, **mas se enganou**\n",
    "- ❌ Falso Negativo: O modelo previu que 91 clientes **não iriam comprar**, **mas eles compram**\n",
    "\n",
    "##### Ou seja, dos **435** clientes que **COMPRAM**, o modelo conseguiu prever corretamente 344 clientes (**79,58%**). Na contramão, o modelo afirmou **292** clientes comprariam, mas errou. Obtivemos um recall ótimo, mas a precisão caiu para **54,10%**, pensando na estratégia de não deixar escapar possíveis compradores, já que como analisamos na segmentação de clientes, a ClickBus possui um grande problema na retenção de novos clientes, então esse é um ótimo resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a74f7f68-4e50-412a-b97f-74c2484a99b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "matriz_de_confusao = confusion_matrix(y_teste, y_pred_com_limiar_ajustado)\n",
    "\n",
    "# Plotando a matriz usando um mapa de calor (heatmap) para melhor visualização\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matriz_de_confusao, \n",
    "            annot=True,      # Mostrando os números dentro de cada quadrado\n",
    "            fmt='d',         # Formatando os números como inteiros\n",
    "            cmap='Blues',    \n",
    "            xticklabels=['Previsto: Não Comprou', 'Previsto: Comprou'],\n",
    "            yticklabels=['Real: Não Comprou', 'Real: Comprou'])\n",
    "\n",
    "plt.xlabel('Previsão do Modelo', fontsize=12)\n",
    "plt.ylabel('Valor Real', fontsize=12)\n",
    "plt.title('Matriz de Confusão do Modelo Final', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8f949c9-a024-42b7-8707-b1184d548e02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Avaliação do Modelo com Curva ROC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57956295-7ff3-4929-b951-27503efe6a55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### A **curva de ROC** ajuda a entender como um modelo se comporta em termos de acerto e erro ao variar o **limiar de decisã**o. Uma **AUC** mais alta indica que o modelo tem maior **capacidade de distinguir entre as duas classes**. No nosso caso, obtivemos um ótimo resultado, um AUC de **85,37%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ea0c0e8-8f81-4769-b17d-50d6b774e8e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Pegamos as probabilidades que o modelo deu para cada cliente ser comprador\n",
    "y_probabilities_final = pipeline_xgb_final.predict_proba(x_teste)[:, 1]\n",
    "\n",
    "# Calculamos a área sob a curva ROC, que mostra o quão bom o modelo é em geral\n",
    "auc_score = roc_auc_score(y_teste, y_probabilities_final)\n",
    "print(f\"A Área Sob a Curva (AUC) do nosso modelo é: {auc_score:.4f}\")\n",
    "\n",
    "# Calculamos os valores que precisamos para desenhar a curva ROC:\n",
    "# a taxa de falsos positivos, a taxa de verdadeiros positivos, e os limiares usados\n",
    "fpr, tpr, thresholds = roc_curve(y_teste, y_probabilities_final)\n",
    "\n",
    "# Começamos a plotar a curva, mostrando como o modelo se comporta\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr, tpr, marker='.', label=f'XGBoost (AUC = {auc_score:.2f})')\n",
    "\n",
    "# Adicionamos a linha do “chute aleatório”, que serve como referência para ver se nosso modelo é melhor que um palpite\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Chute Aleatório (AUC = 0.5)')\n",
    "\n",
    "# Colocamos os títulos e legendas\n",
    "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos (TPR / Recall)')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0292fbbd-fe4d-4821-ae4a-cd170f2b4184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Análise do Modelo: Padrão Identificado na Feature de Recência**\n",
    "\n",
    "##### O modelo identificou que a **recência** é uma variável-chave para prever o comportamento de compra dos clientes. Clientes que realizaram compras **recentemente** têm uma **alta probabilidade** de comprar novamente no mês seguinte, enquanto aqueles que **não compram há mais tempo** tendem a apresentar **menor propensão** a novas compras.\n",
    "\n",
    "##### Esse insight é **fundamental** para direcionar estratégias de **marketing e retenção**, permitindo focar esforços nos clientes com maior potencial de recompra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "229dd6a8-c834-4440-a68d-4e4a70e0ed59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import font_manager as fm\n",
    "\n",
    "# Fazer as previsões com o modelo XGBoost já treinado usando os dados de teste\n",
    "y_pred_xgboost = pipeline_xgb_final.predict(x_teste)\n",
    "\n",
    "# Criar um DataFrame juntando as variáveis de teste com as respostas reais e as previsões do modelo\n",
    "df_resultados_xgboost = x_teste.copy()\n",
    "df_resultados_xgboost['alvo_real'] = y_teste\n",
    "df_resultados_xgboost['previsao'] = y_pred_com_limiar_ajustado\n",
    "\n",
    "# Função para classificar cada previsão em verdadeiro positivo, verdadeiro negativo, falso positivo ou falso negativo\n",
    "def classificar_resultado(row):\n",
    "    if row['alvo_real'] == 1 and row['previsao'] == 1:\n",
    "        return 'Verdadeiro Positivo — Acertou que ia comprar'\n",
    "    elif row['alvo_real'] == 0 and row['previsao'] == 0:\n",
    "        return 'Verdadeiro Negativo — Acertou que não ia comprar,'\n",
    "    elif row['alvo_real'] == 0 and row['previsao'] == 1:\n",
    "        return 'Falso Positivo — Previu compra, mas não comprou'\n",
    "    else:  # alvo_real == 1 and previsao == 0\n",
    "        return 'Falso Negativo — Previu que não compraria, mas comprou'\n",
    "\n",
    "# Aplicar essa classificação para cada linha do DataFrame\n",
    "df_resultados_xgboost['resultado'] = df_resultados_xgboost.apply(classificar_resultado, axis=1)\n",
    "\n",
    "# Calcular quantos acertos e erros o modelo teve\n",
    "acertos = df_resultados_xgboost['resultado'].str.startswith('Verdadeiro').sum()\n",
    "erros = df_resultados_xgboost['resultado'].str.startswith('Falso').sum()\n",
    "\n",
    "print(f\"Total de acertos: {acertos}\")\n",
    "print(f\"Total de erros: {erros}\")\n",
    "print(f\"Taxa de acerto geral: {acertos / (acertos + erros) * 100:.2f}%\")\n",
    "\n",
    "# Criar um gráfico de dispersão para visualizar como os acertos e erros estão distribuídos\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.scatterplot(\n",
    "    data=df_resultados_xgboost,\n",
    "    x='recencia',\n",
    "    y='frequencia',\n",
    "    hue='resultado',\n",
    "    palette = {\n",
    "        'Verdadeiro Positivo — Acertou que ia comprar': '#2ecc71', \n",
    "        'Verdadeiro Negativo — Acertou que não ia comprar,': '#3498db', \n",
    "        'Falso Positivo — Previu compra, mas não comprou': '#f39c12', \n",
    "        'Falso Negativo — Previu que não compraria, mas comprou': '#e74c3c' \n",
    "    },\n",
    "    hue_order=[\n",
    "        'Verdadeiro Positivo — Acertou que ia comprar',\n",
    "        'Verdadeiro Negativo — Acertou que não ia comprar,',\n",
    "        'Falso Positivo — Previu compra, mas não comprou',\n",
    "        'Falso Negativo — Previu que não compraria, mas comprou'\n",
    "    ],\n",
    "    alpha=0.7,\n",
    "    s=80\n",
    ")\n",
    "\n",
    "# Definir títulos e labels\n",
    "plt.title('Análise Visual dos Acertos e Erros (XGBoost)', fontdict={'fontsize': 16}, pad=15)\n",
    "plt.xlabel('Recência (Dias desde a última compra)')\n",
    "plt.ylabel('Frequência (Total de compras)')\n",
    "\n",
    "# Ajustar a legenda para ficar com título em negrito e fonte maior\n",
    "plt.legend(title='Resultado da Previsão', title_fontproperties=fm.FontProperties(weight='bold', size=12), fontsize=11)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c03e035b-92d3-471e-8d67-30bb1b19eed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Podemos confirmar a importância da **recência** analisando o atributo `.feature_importances_` do modelo XGBoost, que indica o peso de cada feature na decisão do modelo. Em seguida, plotamos um gráfico para visualizar essas importâncias de forma clara.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5681faf2-6107-4478-92ed-a09f4058aaf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Acessar o modelo XGBoost dentro do pipeline já treinado\n",
    "modelo_final_acessado = pipeline_xgb_final.named_steps['xgb']\n",
    "\n",
    "# Pegar a importância que o modelo deu para cada feature\n",
    "importancias = modelo_final_acessado.feature_importances_\n",
    "\n",
    "# Montar um DataFrame para organizar e ordenar as importâncias\n",
    "df_importancias_final = pd.DataFrame({\n",
    "    'feature': x_treino.columns,\n",
    "    'importance': importancias\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Plotar um gráfico de barras para visualizar quais features são mais relevantes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    data=df_importancias_final,\n",
    "    palette='rocket'\n",
    ")\n",
    "plt.title('Importância das Features - Clientes Comuns')\n",
    "plt.xlabel('Score de Importância (XGBoost)')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ae01a1a-d203-477c-8ac4-ebc381e71dac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Entrega Final dos Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edce128c-92b7-4da5-8526-6ec9f5174622",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pegando os IDs dos clientes correspondentes ao x_teste\n",
    "ids_para_entrega = df_final_teste.loc[x_teste.index, 'fk_contact']\n",
    "\n",
    "# Criando o DataFrame final de entrega\n",
    "df_entrega = pd.DataFrame({\n",
    "    'fk_contact': ids_para_entrega,\n",
    "    'alvo_real': y_teste,  \n",
    "    'previsao': y_pred_com_limiar_ajustado,\n",
    "    'probabilidade_de_compra': y_probabilities_final\n",
    "})\n",
    "\n",
    "# Criando uma coluna que verifica se o modelo acertou ou errou\n",
    "df_entrega['resultado'] = np.where(df_entrega['alvo_real'] == df_entrega['previsao'], 'Acerto', 'Erro')\n",
    "\n",
    "# Ajustando o índice\n",
    "df_entrega = df_entrega.set_index(x_teste.index)\n",
    "\n",
    "df_entrega.head()\n",
    "\n",
    "### Salvando o DataFrame final em um arquivo CSV\n",
    "# df_entrega.to_csv('entrega_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11283772-839c-4319-aa23-c51608f4ab7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6cd807b-a10a-41a9-a12a-640e70385c70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Conclusão do Projeto**\n",
    "\n",
    "### **Objetivo**\n",
    "Criar um modelo para prever se clientes \"Comuns\" vão comprar de novo nos próximos 30 dias.\n",
    "\n",
    "### Resultados\n",
    "- **AUC:** 84% — separa muito bem quem compra e quem não compra.  \n",
    "- **Threshold:** 0,3 para priorizar **Recall**.  \n",
    "- **Recall:** 79% (344 de 435 compradores identificados).  \n",
    "- **Precisão:** 54% (trade-off esperado por priorizar recall).  \n",
    "- **F1-Score:** Evoluímos de 28% para 64%.  \n",
    "- **Acurácia:** 74,4% no total.  \n",
    "\n",
    "### Insights\n",
    "- **Recência importa:** clientes que compraram recentemente têm maior chance de voltar a comprar.  \n",
    "- **Engajamento pesa:** frequência de compras e gasto total são fatores relevantes.  \n",
    "- **Padrão claro:** baixa recência + alta frequência = alta chance de recompra.  \n",
    "\n",
    "### Próximos Passos\n",
    "1. Criar campanhas direcionadas a clientes com probabilidade de compra superior a 30%.  \n",
    "2. Focar em ações de reativação para clientes que estão há mais tempo sem comprar.  \n",
    "3. Rodar previsões semanais/mensais e ajustar o modelo conforme os resultados.  \n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "estudo_modelo_previsao_compra_30_dias",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
